{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/notebook/poc\n",
      "../../model/mallet_weights_50_2019_01_15\n",
      "../../data/processed/dictionary.dict\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('../../model/mallet_weights_50_2019_01_15')\n",
    "dictionary_path = os.path.join('../../data/processed/dictionary.dict')\n",
    "label_definition_path = os.path.join('../../data/processed/Topic Definition_2019_01_15.npy')\n",
    "text_file_path = \"../../documentation/sample_docs/5138964-v5-Brazil_2013_Article_IV_Consultation_-_Policy_Note.DOCX\"\n",
    "processed_file_path = os.path.join('../../data/processed/', text_file_path.split(sep='/')[-1].split(sep ='.')[0]+'.csv')\n",
    "print(os.getcwd())\n",
    "print(model_path)\n",
    "print(dictionary_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Model, Dictionary, and Label (manually created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:random_state not set so using default value\n",
      "WARNING:root:failed to load state from ../../model/mallet_weights_50_2019_01_15.state: [Errno 2] No such file or directory: '../../model/mallet_weights_50_2019_01_15.state'\n"
     ]
    }
   ],
   "source": [
    "lda_model = LdaModel.load(model_path)\n",
    "old_dict = corpora.Dictionary.load(dictionary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_topic_dict = np.load(label_definition_path)\n",
    "label_topic_dict = dict(label_topic_dict.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model Topic Dictionary (Topic ID ~ Word List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_topic_list = lda_model.show_topics(num_topics= 50, num_words= 15, formatted= False)\n",
    "model_topic_list = dict(model_topic_list)\n",
    "\n",
    "model_topic_dict = dict()\n",
    "\n",
    "for key, value in model_topic_list.items():\n",
    "    word_list, prob = zip(*value)\n",
    "    model_topic_dict[key] = list(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Topic-Lable Mapping by applying IOU to manually-created labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_Intersection_Over_Union(list_a, list_b):\n",
    "    \n",
    "    inter_set = list(set(list_a) & set(list_b))\n",
    "    union_set = list(set(list_a) | set(list_b))\n",
    "    \n",
    "    return len(inter_set)/len(union_set)\n",
    "\n",
    "def Map_Topic_Label(model_dict, label_dict):\n",
    "    \n",
    "    new_list =dict()\n",
    "    \n",
    "    for model_key, model_value in model_dict.items():\n",
    "        iou_list =[]\n",
    "        for label_key, label_value in label_dict.items():\n",
    "            iou_list.append(Calculate_Intersection_Over_Union(model_value, label_value))\n",
    "        max_id = np.array(iou_list).argmax()\n",
    "        new_list[model_key] = list(label_dict.keys())[max_id]\n",
    "    \n",
    "    return new_list\n",
    "\n",
    "topic_label_dict = Map_Topic_Label(model_dict= model_topic_dict, label_dict= label_topic_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_Doc(f_path,word_length_filter=20):\n",
    "    if os.path.isfile(f_path):\n",
    "        doc = Document(f_path)\n",
    "        text_list = [p.text for p in doc.paragraphs if len(p.text)>10]#[3:]\n",
    "        text_list = [p.replace('\\xa0',' ') for p in text_list] # some clean up \n",
    "        text_list = [p for p in text_list if len(p.split()) > word_length_filter]\n",
    "    else:\n",
    "        raise Exception('File does not exist: {}'.format(f_path))\n",
    "\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = Read_Doc(text_file_path)\n",
    "\n",
    "new_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en') \n",
    "\n",
    "def Infer_One_Paragraph(paragraph, ldaModel):\n",
    "    '''Load raw paragraph and model, return cleaned paragraph and topic_label with highest probability'''\n",
    "    #### Process text using Spacy for Tokenization and loaded dictionary for bag-of-words\n",
    "    new_text = nlp(paragraph)\n",
    "    new_doc = [word.text for word in new_text]\n",
    "    new_bow = old_dict.doc2bow(new_doc)\n",
    "    \n",
    "    ## Make inference and retrieve Top ID\n",
    "    topic_prob = ldaModel[new_bow]\n",
    "    n, prob = zip(*topic_prob)\n",
    "    top_id = np.array(n)[np.array(prob).argmax()]\n",
    "    \n",
    "    return new_text, top_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [Infer_One_Paragraph(paragraph, lda_model) for paragraph in new_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, topic_id = zip(*result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'Paragraph': p, 'Topic ID' : topic_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.Paragraph.apply(str)\n",
    "result['Label'] = result['Topic ID'].apply(lambda x: topic_label_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(processed_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
