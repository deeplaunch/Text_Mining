{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trending topics\n",
    "\n",
    "#### While topic modeling such as LDA seems to be an easy tool to identify topics, my past experience using it showed three drawbacks when it comes to short and high-frequency content.\n",
    "\n",
    "1. Once an unsupervised model is selected, classfications become static, which means \"unseen\" topics in the future won't be able to be captured.\n",
    "\n",
    "2. Short messages are more likely to contain a homogenous topic than not, which challenges LDA's assumption of a probability distribution of \"multiple\" topics in each document.\n",
    "\n",
    "3. Ultimately LDA is a statistical model that isn't quite able capture similar semantics of words\n",
    "\n",
    "#### Instead, here I build a *\"live\"* pipeline of trending topic detector combining several techniques such as Doc2Vec and hierachical clustering. This approach allws us to focus on recent documents, regardless what the past topic distribution might look like.\n",
    "\n",
    "\n",
    "#### _Please note: here I don't have any API for news feed, thus using a file sent from a friend of mine. However the approach is similar._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import xlrd\n",
    "import matplotlib as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load and Clean file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8213, 19)\n",
      "Index(['DATE', 'TIME', 'UNIQUE_STORY_INDEX', 'EVENT_TYPE', 'PNAC',\n",
      "       'STORY_DATE_TIME', 'TAKE_DATE_TIME', 'HEADLINE_ALERT_TEXT',\n",
      "       'ACCUMULATED_STORY_TEXT', 'TAKE_TEXT', 'PRODUCTS', 'TOPICS',\n",
      "       'RELATED_RICS', 'NAMED_ITEMS', 'HEADLINE_SUBTYPE', 'STORY_TYPE',\n",
      "       'TABULAR_FLAG', 'ATTRIBUTION', 'LANGUAGE'],\n",
      "      dtype='object')\n",
      "(3137, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3137"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.read_csv('sample_file.csv') \n",
    "print(text_df.shape)\n",
    "print(text_df.columns)\n",
    "\n",
    "# remove rows that indicates \"please ignore\"\n",
    "text_df = text_df[text_df.HEADLINE_ALERT_TEXT.str.contains(\"Test, Please Ignore\")==False]\n",
    "text_df.LANGUAGE.value_counts()\n",
    "\n",
    "#### Only English\n",
    "text_df = text_df[text_df['LANGUAGE']=='EN']\n",
    "\n",
    "## Use Headline when no Take Text is available\n",
    "text_df.loc[text_df['TAKE_TEXT'].isnull(),'TAKE_TEXT'] = text_df.loc[text_df['TAKE_TEXT'].isnull(),'HEADLINE_ALERT_TEXT']\n",
    "\n",
    "## fill missing time\n",
    "text_df.DATE = text_df.DATE.fillna(method = 'ffill')\n",
    "text_df.TIME = text_df.TIME.fillna(method = 'ffill')\n",
    "\n",
    "## format time\n",
    "\n",
    "text_df.DATE = pd.to_datetime(text_df.DATE)\n",
    "text_df['HOUR'] = text_df.TIME.apply(lambda x: x.split(':')[0])\n",
    "\n",
    "# cleaning text\n",
    "text_df.TAKE_TEXT = text_df.TAKE_TEXT.str.lower().str.strip().str.replace('[^\\w\\s]''',' ').str.replace('[^a-zA-Z0-9'' ]',' ').str.replace(r'\\W*\\b\\w{1,1}\\b', '')\n",
    "\n",
    "text_df.TAKE_TEXT = text_df.TAKE_TEXT.apply(lambda x: re.sub(r'[\\*|\\+|\\_|\\-|\\<||>|\\(|\\)]','',x))\n",
    "\n",
    "text_df = text_df[text_df.TAKE_TEXT.notnull()]\n",
    "\n",
    "# apply gensim processing\n",
    "text_df['TAKE_TEXT'] = text_df['TAKE_TEXT'].apply(gensim.utils.simple_preprocess)\n",
    "print(text_df.shape)\n",
    "\n",
    "train_corpus = text_df.TAKE_TEXT.tolist()\n",
    "train_corpus = [gensim.models.doc2vec.TaggedDocument(value, [key])for key , value in enumerate(train_corpus)]\n",
    "len(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train a Doc2Vec Model quickly (can also use a pre-trained model from wiki for transfer-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=100)\n",
    "\n",
    "# build vocabulary\n",
    "model.build_vocab(train_corpus)\n",
    "\n",
    "# train model\n",
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    second_ranks.append(sims[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some test of the model ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Document (476): «june infostrada sports result from the pirelli russian cup final match on saturday final saturday june cska moscow anzhi makhachkala halftime mins penalty shootout cska moscow win on penalties keywords soccer russia cup results»\n",
      "\n",
      "Similar Document (855, 0.897797167301178): «june infostrada sports result from the romanian cup final match on saturday final saturday june petrolul ploiesti cfr cluj halftime keywords soccer romania cup results»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random check to see similar documents are indeed identified (cltr-end for a few examples)\n",
    "doc_id = np.random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Selected Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cluster documents for topic identification using Hierachical Agglomerative Clustering\n",
    "#### Here clustering is executed in each time window (4 hours as I choose). We are able to identify the top topic in each time window (my defiintion of \"trending\"). Such \"onlineness\" is a key feature of this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(ls):\n",
    "    return max(set(ls), key=ls.count)\n",
    "\n",
    "def find_largest_topic(vector):\n",
    "    \n",
    "    cluster = AgglomerativeClustering(n_clusters= 140, linkage='ward')  # Here we want many clusters to get smaller ones\n",
    "    cluster.fit_predict(vector)\n",
    "    max_id = most_common(list(cluster.labels_))\n",
    "    result_id = (cluster.labels_ == max_id)\n",
    "    \n",
    "    return result_id \n",
    "\n",
    "text_df['vector'] = [model.infer_vector(x.words) for x in train_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break data into 4-hour window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = text_df\n",
    "result_df.HOUR = result_df.HOUR.apply(float)\n",
    "n = int(result_df.HOUR.max() / 4)\n",
    "result_df['Hour_4'] = pd.qcut(result_df.HOUR, n , labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list =[]\n",
    "\n",
    "for x in range(n):\n",
    "    vector = result_df.loc[result_df.Hour_4 == x, 'vector'].tolist()\n",
    "    top_topic_id = find_largest_topic(vector)\n",
    "    top_docs = result_df.loc[result_df.Hour_4 == x, 'TAKE_TEXT'][top_topic_id]\n",
    "    topic_list.append(top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25                       [top, news, investment, banking]\n",
       "151     [service, alert, msci, world, and, us, eod, de...\n",
       "609     [exxon, mobil, xom, reports, unplanned, flarin...\n",
       "610     [exxon, reports, unplanned, flaring, breakdown...\n",
       "613                           [update, baseball, results]\n",
       "1108                             [top, news, front, page]\n",
       "1942                                    [emea, test, rcf]\n",
       "2224                             [top, news, front, page]\n",
       "2227                             [top, news, front, page]\n",
       "2467                             [top, news, front, page]\n",
       "3331    [motorcycling, motorcycling, grand, prix, moto...\n",
       "4395    [service, alert, datascope, equities, planned,...\n",
       "4932                                 [diary, japan, june]\n",
       "5602                                     [diary, vietnam]\n",
       "5607      [korea, may, manufacturing, pmi, vs, in, april]\n",
       "5616               [buzz, eur, aud, uptrend, strong, for]\n",
       "5622    [japan, corporate, capital, spending, falls, p...\n",
       "6032    [north, american, power, transmission, outage,...\n",
       "6565    [tennis, nadal, looks, for, renewed, vigour, a...\n",
       "6568                    [taiwan, may, pmi, vs, in, april]\n",
       "6570                    [taiwan, may, pmi, vs, in, april]\n",
       "6580                    [taiwan, pmi, slips, to, in, may]\n",
       "6589                        [top, news, asian, companies]\n",
       "7099                 [diary, singapore, events, to, july]\n",
       "7101           [technicals, lme, aluminium, to, drop, to]\n",
       "7104       [keywords, commodities, technicals, aluminium]\n",
       "7105    [service, alert, thomson, reuters, dealing, em...\n",
       "7112                  [reuters, insider, upcoming, shows]\n",
       "Name: TAKE_TEXT, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not as clean as I would ideatlly like, \n",
    "# But similar document do get clustered together (e.g. market/economy and sports). \n",
    "# We may further fine-tune it.\n",
    "topic_list[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identify the \"Names\" in the largest topic using TF-IDF\n",
    "#### Here alternatively we can retreive most frequent words that are in the largest topic but not the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['accessed', 'account', 'accused', 'action', 'activity', 'added',\n",
       "       'adding', 'additional', 'affect', 'african', 'agency', 'ago',\n",
       "       'agreed', 'agreement', 'agriculture', 'air', 'al', 'alex', 'allow',\n",
       "       'allowed', 'amid', 'analysis', 'analyst', 'analysts', 'announced',\n",
       "       'annual', 'anti', 'appeared', 'approved', 'apr', 'arab', 'area',\n",
       "       'areas', 'argentina', 'asked', 'assets', 'atletico', 'attack',\n",
       "       'aud', 'aug', 'australian', 'authorities', 'available', 'away',\n",
       "       'ax', 'backs', 'bad', 'balance', 'bankers', 'barcelona', 'base',\n",
       "       'baseball', 'basis', 'battle', 'bay', 'beat', 'beckons', 'began',\n",
       "       'begin', 'beijing', 'believe', 'ben', 'benchmark', 'best',\n",
       "       'better', 'biggest', 'bln', 'bo', 'board', 'boj', 'bombs', 'bond',\n",
       "       'booms', 'boost', 'border', 'boston', 'brackets', 'brazil',\n",
       "       'break', 'brien', 'bring', 'british', 'broader', 'budget',\n",
       "       'building', 'bureau', 'business', 'buy', 'buying', 'buys', 'buzz',\n",
       "       'ca', 'california', 'called', 'calls', 'came', 'campaign',\n",
       "       'cancer', 'capacity', 'caps', 'career', 'case', 'cash', 'caused',\n",
       "       'cautious', 'center', 'centre', 'ceo', 'chairman', 'challenge',\n",
       "       'champion', 'champions', 'championship', 'chance', 'change',\n",
       "       'chart', 'chicago', 'chinese', 'claims', 'clare', 'clash',\n",
       "       'clashes', 'class', 'clear', 'client', 'closed', 'club', 'coach',\n",
       "       'coal', 'codes', 'comam', 'comas', 'come', 'comem', 'coming',\n",
       "       'comment', 'comments', 'commercial', 'commission', 'committee',\n",
       "       'communications', 'compared', 'compiled', 'complete', 'completed',\n",
       "       'concern', 'concerns', 'conditions', 'conference', 'confirmed',\n",
       "       'conflict', 'consecutive', 'considered', 'construction', 'contact',\n",
       "       'continue', 'contract', 'control', 'copper', 'corp', 'corporate',\n",
       "       'cost', 'costs', 'council', 'countries', 'course', 'court',\n",
       "       'crackdown', 'created', 'credit', 'cricket', 'crisis', 'cross',\n",
       "       'crowd', 'cup', 'current', 'currently', 'cuts', 'cyber', 'daily',\n",
       "       'damage', 'days', 'deadly', 'deal', 'death', 'dec', 'decade',\n",
       "       'december', 'decision', 'declared', 'declined', 'defaulters',\n",
       "       'deficit', 'delays', 'delivery', 'demand', 'department', 'deriv',\n",
       "       'desks', 'detailed', 'development', 'diary', 'did', 'died',\n",
       "       'different', 'difficult', 'director', 'does', 'doing', 'dollar',\n",
       "       'dollars', 'domestic', 'don', 'double', 'drop', 'dropped', 'drug',\n",
       "       'du', 'dubai', 'dx', 'ea', 'earlier', 'earnings', 'eastern', 'ecb',\n",
       "       'econ', 'edges', 'ef', 'effect', 'efforts', 'election', 'emea',\n",
       "       'emergency', 'ended', 'ends', 'england', 'ent', 'equities',\n",
       "       'erdogan', 'eric', 'estimated', 'eu', 'euro', 'euros', 'evans',\n",
       "       'event', 'events', 'exclusive', 'executive', 'expect',\n",
       "       'expectations', 'export', 'exports', 'eye', 'eyes', 'face',\n",
       "       'faces', 'facility', 'factors', 'factory', 'failed', 'fall',\n",
       "       'fallon', 'falls', 'family', 'fast', 'fears', 'feature', 'feb',\n",
       "       'fed', 'federal', 'fell', 'fellow', 'field', 'fifth', 'fight',\n",
       "       'fighting', 'figures', 'finals', 'finance', 'finish', 'finished',\n",
       "       'firm', 'focus', 'follow', 'followed', 'food', 'force', 'forced',\n",
       "       'forces', 'forecast', 'forex', 'form', 'fourth', 'frankfurt',\n",
       "       'free', 'freeport', 'fteu', 'ftseurofirst', 'fuel', 'funds',\n",
       "       'future', 'futures', 'gain', 'gains', 'game', 'games', 'garros',\n",
       "       'gave', 'gdp', 'german', 'germany', 'getting', 'given', 'giving',\n",
       "       'goal', 'going', 'gol', 'golf', 'good', 'got', 'governor',\n",
       "       'graham', 'grand', 'great', 'ground', 'groups', 'growing',\n",
       "       'guides', 'gulf', 'ha', 'half', 'hand', 'hands', 'hard', 'having',\n",
       "       'head', 'headline', 'heavy', 'held', 'helped', 'hezbollah',\n",
       "       'higher', 'highest', 'hits', 'hk', 'hold', 'holding', 'holdings',\n",
       "       'holds', 'homes', 'hong', 'hope', 'hopes', 'hour', 'hours',\n",
       "       'house', 'houston', 'hsbc', 'hundreds', 'immediately', 'impact',\n",
       "       'important', 'imports', 'include', 'included', 'increase',\n",
       "       'increased', 'indian', 'industrial', 'industry', 'inflation',\n",
       "       'infosys', 'infrastructure', 'initial', 'injured', 'injuries',\n",
       "       'inr', 'int', 'interview', 'invasion', 'investigation', 'investor',\n",
       "       'involved', 'iran', 'iraq', 'irish', 'islamist', 'issue', 'issues',\n",
       "       'italian', 'italy', 'jakarta', 'jan', 'january', 'japanese', 'job',\n",
       "       'jobs', 'john', 'join', 'joined', 'jp', 'jpy', 'jul', 'july',\n",
       "       'kept', 'kevin', 'king', 'know', 'known', 'kong', 'korean',\n",
       "       'kuchar', 'kyn', 'la', 'labour', 'lack', 'large', 'largely',\n",
       "       'largest', 'law', 'lcoc', 'leader', 'leaders', 'leading', 'league',\n",
       "       'lebanon', 'led', 'left', 'legal', 'levels', 'liga', 'like',\n",
       "       'likely', 'limited', 'line', 'lions', 'list', 'little', 'lives',\n",
       "       'lme', 'london', 'longer', 'look', 'looking', 'los', 'loss',\n",
       "       'losses', 'lost', 'lot', 'louis', 'lower', 'lowest', 'lz',\n",
       "       'madrid', 'mail', 'main', 'maintenance', 'makes', 'making',\n",
       "       'malaysia', 'man', 'management', 'manager', 'manhattan',\n",
       "       'manufacturing', 'mar', 'march', 'mark', 'martin', 'match',\n",
       "       'matches', 'means', 'measures', 'medical', 'meet', 'meeting',\n",
       "       'melanoma', 'member', 'members', 'memorial', 'men', 'met',\n",
       "       'mexico', 'miami', 'michael', 'mid', 'mike', 'military',\n",
       "       'ministry', 'minutes', 'missing', 'mln', 'momentum', 'monetary',\n",
       "       'monthly', 'moody', 'morgan', 'morning', 'motorcycling', 'mumbai',\n",
       "       'murthy', 'mw', 'nadal', 'narayana', 'nation', 'nations', 'nba',\n",
       "       'near', 'nearly', 'needed', 'needs', 'newspaper', 'nick', 'night',\n",
       "       'non', 'note', 'nov', 'november', 'ns', 'nuclear', 'number', 'ny',\n",
       "       'nymex', 'obama', 'oct', 'october', 'offer', 'offers', 'office',\n",
       "       'officials', 'oklahoma', 'opened', 'opening', 'operations',\n",
       "       'opposition', 'order', 'outage', 'outages', 'outlook', 'output',\n",
       "       'outside', 'overall', 'overseas', 'owned', 'pacific', 'pakistan',\n",
       "       'paper', 'paris', 'park', 'parliament', 'party', 'pass', 'past',\n",
       "       'patients', 'patrick', 'paul', 'pay', 'peace', 'period', 'perry',\n",
       "       'personnel', 'peter', 'philippines', 'pittsburgh', 'pjm', 'place',\n",
       "       'plan', 'planned', 'plant', 'play', 'played', 'player', 'players',\n",
       "       'playing', 'pm', 'policy', 'poll', 'poor', 'popular', 'port',\n",
       "       'position', 'possible', 'post', 'potential', 'pr', 'pre',\n",
       "       'preliminary', 'presidency', 'press', 'previous', 'previously',\n",
       "       'prime', 'private', 'prix', 'pro', 'problem', 'problems',\n",
       "       'process', 'production', 'profit', 'project', 'property',\n",
       "       'protest', 'protesters', 'pts', 'pulled', 'push', 'pushing',\n",
       "       'qatar', 'quarter', 'quotes', 'qusair', 'raise', 'raised',\n",
       "       'raises', 'raising', 'rally', 'range', 'rare', 'rating', 'ratings',\n",
       "       'reach', 'reached', 'really', 'reason', 'rebel', 'rebels',\n",
       "       'recalls', 'received', 'receiving', 'recent', 'record', 'recovery',\n",
       "       'reduce', 'refer', 'reform', 'reforms', 'region', 'regular',\n",
       "       'related', 'release', 'released', 'remain', 'remained', 'remains',\n",
       "       'removed', 'reported', 'reporters', 'reports', 'republic',\n",
       "       'republican', 'request', 'res', 'research', 'reserve',\n",
       "       'resistance', 'resources', 'response', 'result', 'return',\n",
       "       'returned', 'returns', 'revenue', 'review', 'revised', 'richard',\n",
       "       'right', 'rights', 'rises', 'rising', 'risk', 'rival', 'river',\n",
       "       'robert', 'rock', 'roland', 'role', 'rose', 'row', 'rugby',\n",
       "       'rules', 'run', 'running', 'rupees', 'russia', 'russian', 'sale',\n",
       "       'san', 'saudi', 'saw', 'say', 'saying', 'scandal', 'scandals',\n",
       "       'schedule', 'scheduled', 'scored', 'se', 'season', 'sector',\n",
       "       'securities', 'security', 'seed', 'seek', 'sees', 'sell',\n",
       "       'selling', 'send', 'senior', 'sent', 'sentiment', 'seoul', 'sep',\n",
       "       'september', 'sets', 'share', 'sharply', 'short', 'shot', 'shows',\n",
       "       'shrinks', 'shut', 'signal', 'signs', 'similar', 'simon',\n",
       "       'singles', 'situation', 'slow', 'slowing', 'small', 'smithfield',\n",
       "       'social', 'sociedad', 'soft', 'sold', 'source', 'sources',\n",
       "       'southern', 'sox', 'spanish', 'speculation', 'speech', 'speed',\n",
       "       'spending', 'spokesman', 'spokeswoman', 'spot', 'spx', 'squad',\n",
       "       'square', 'st', 'stage', 'stake', 'standard', 'standings',\n",
       "       'stanley', 'started', 'starting', 'statement', 'station',\n",
       "       'statistics', 'stay', 'steady', 'step', 'stephen', 'stimulus',\n",
       "       'stop', 'storm', 'straight', 'street', 'streets', 'strong',\n",
       "       'stronger', 'struggling', 'study', 'subsequent', 'suit', 'summit',\n",
       "       'sun', 'super', 'supply', 'surrenders', 'survey', 'sweden',\n",
       "       'swiss', 'sydney', 'syria', 'syrian', 'table', 'taiwan', 'taken',\n",
       "       'takes', 'taking', 'talk', 'talks', 'target', 'tax', 'tech',\n",
       "       'television', 'term', 'terms', 'tests', 'text', 'things', 'think',\n",
       "       'thomsonone', 'thousands', 'thursday', 'title', 'today', 'tokyo',\n",
       "       'tom', 'tony', 'took', 'tornadoes', 'tough', 'tour', 'tournament',\n",
       "       'town', 'traders', 'trading', 'training', 'transmission',\n",
       "       'treatment', 'trial', 'tried', 'try', 'trying', 'tuesday',\n",
       "       'turkey', 'turkish', 'turn', 'twitter', 'type', 'uk',\n",
       "       'unemployment', 'union', 'unit', 'university', 'unrest', 'updates',\n",
       "       'usa', 'usd', 'use', 'used', 'user', 'utilities', 've', 'victory',\n",
       "       'vietnam', 'violence', 'volume', 'vote', 'vs', 'wall', 'want',\n",
       "       'wants', 'war', 'watch', 'water', 'way', 'weak', 'weaker',\n",
       "       'weather', 'website', 'wednesday', 'weekend', 'weekly', 'weeks',\n",
       "       'went', 'west', 'western', 'wheat', 'white', 'wind', 'winds',\n",
       "       'winner', 'wins', 'women', 'won', 'work', 'workers', 'working',\n",
       "       'worst', 'worth', 'www', 'xau', 'xi', 'yankees', 'yen', 'yield',\n",
       "       'yields', 'young', 'yr', 'zb', 'zealand', 'zone'], dtype='<U14')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a tfidf on entire corpus\n",
    "tfidf = TfidfVectorizer(tokenizer=word_tokenize, stop_words='english', min_df=0.01, max_df=0.035)   \n",
    "X_train = list(map(lambda x: ' '.join(word for word in x), result_df.TAKE_TEXT))\n",
    "vect = tfidf.fit(X_train)\n",
    "feature = np.array(vect.get_feature_names())\n",
    "print(len(feature))\n",
    "\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['outage', 'aud', 'equities', 'maintenance', 'pjm', 'spending',\n",
       "       'corporate', 'falls', 'nadal', 'prix', 'shows', 'lme', 'vietnam',\n",
       "       'reports', 'ca', 'emea', 'motorcycling', 'vs', 'diary', 'taiwan'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exaample\n",
    "test = [x for y in topic_list[0] for x in y ]\n",
    "test = ' '.join(test)\n",
    "test\n",
    "x = tfidf.transform([test])\n",
    "y = x.toarray()[0].argsort()[-20:]\n",
    "y\n",
    "\n",
    "feature[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to each topic list to get most distinct words withitn the topic\n",
    "def get_top_words(docs):\n",
    "    \n",
    "    # merge top topic into one document for tf-idf performance\n",
    "    docs = [x for y in docs for x in y ] \n",
    "    docs =[' '.join(docs)]\n",
    "    \n",
    "    # get tf-idf and sort words by returned value\n",
    "    tfidf = vect.transform(docs)\n",
    "    sorted_tfidf_index = tfidf.toarray()[0].argsort()[-15:]\n",
    "    df = pd.DataFrame(data = feature[sorted_tfidf_index], columns=['vocab'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "result = [get_top_words(x) for x in topic_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spending</td>\n",
       "      <td>buzz</td>\n",
       "      <td>st</td>\n",
       "      <td>ns</td>\n",
       "      <td>ftseurofirst</td>\n",
       "      <td>fteu</td>\n",
       "      <td>buzz</td>\n",
       "      <td>freeport</td>\n",
       "      <td>fteu</td>\n",
       "      <td>fteu</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>future</td>\n",
       "      <td>gain</td>\n",
       "      <td>championship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corporate</td>\n",
       "      <td>standings</td>\n",
       "      <td>target</td>\n",
       "      <td>men</td>\n",
       "      <td>fuel</td>\n",
       "      <td>communications</td>\n",
       "      <td>baseball</td>\n",
       "      <td>fteu</td>\n",
       "      <td>ftseurofirst</td>\n",
       "      <td>ftseurofirst</td>\n",
       "      <td>fuel</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>futures</td>\n",
       "      <td>grand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>falls</td>\n",
       "      <td>championship</td>\n",
       "      <td>weather</td>\n",
       "      <td>holding</td>\n",
       "      <td>funds</td>\n",
       "      <td>target</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>ftseurofirst</td>\n",
       "      <td>fuel</td>\n",
       "      <td>fuel</td>\n",
       "      <td>funds</td>\n",
       "      <td>free</td>\n",
       "      <td>future</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nadal</td>\n",
       "      <td>sees</td>\n",
       "      <td>baseball</td>\n",
       "      <td>maintenance</td>\n",
       "      <td>future</td>\n",
       "      <td>outlook</td>\n",
       "      <td>white</td>\n",
       "      <td>funds</td>\n",
       "      <td>gains</td>\n",
       "      <td>funds</td>\n",
       "      <td>usd</td>\n",
       "      <td>freeport</td>\n",
       "      <td>free</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prix</td>\n",
       "      <td>resistance</td>\n",
       "      <td>grand</td>\n",
       "      <td>singles</td>\n",
       "      <td>futures</td>\n",
       "      <td>weather</td>\n",
       "      <td>research</td>\n",
       "      <td>fuel</td>\n",
       "      <td>frankfurt</td>\n",
       "      <td>future</td>\n",
       "      <td>play</td>\n",
       "      <td>fteu</td>\n",
       "      <td>funds</td>\n",
       "      <td>doing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shows</td>\n",
       "      <td>mail</td>\n",
       "      <td>research</td>\n",
       "      <td>volume</td>\n",
       "      <td>gain</td>\n",
       "      <td>baseball</td>\n",
       "      <td>holding</td>\n",
       "      <td>trading</td>\n",
       "      <td>gain</td>\n",
       "      <td>futures</td>\n",
       "      <td>buzz</td>\n",
       "      <td>form</td>\n",
       "      <td>zone</td>\n",
       "      <td>prix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lme</td>\n",
       "      <td>italy</td>\n",
       "      <td>raises</td>\n",
       "      <td>malaysia</td>\n",
       "      <td>gains</td>\n",
       "      <td>qatar</td>\n",
       "      <td>rupees</td>\n",
       "      <td>italy</td>\n",
       "      <td>futures</td>\n",
       "      <td>gain</td>\n",
       "      <td>stronger</td>\n",
       "      <td>funds</td>\n",
       "      <td>ftseurofirst</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vietnam</td>\n",
       "      <td>grand</td>\n",
       "      <td>prix</td>\n",
       "      <td>doing</td>\n",
       "      <td>game</td>\n",
       "      <td>research</td>\n",
       "      <td>raises</td>\n",
       "      <td>baseball</td>\n",
       "      <td>future</td>\n",
       "      <td>gains</td>\n",
       "      <td>result</td>\n",
       "      <td>fuel</td>\n",
       "      <td>fteu</td>\n",
       "      <td>planned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reports</td>\n",
       "      <td>rating</td>\n",
       "      <td>russia</td>\n",
       "      <td>prix</td>\n",
       "      <td>freeport</td>\n",
       "      <td>equities</td>\n",
       "      <td>holdings</td>\n",
       "      <td>grand</td>\n",
       "      <td>line</td>\n",
       "      <td>standings</td>\n",
       "      <td>cross</td>\n",
       "      <td>grand</td>\n",
       "      <td>fuel</td>\n",
       "      <td>maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ca</td>\n",
       "      <td>moody</td>\n",
       "      <td>rating</td>\n",
       "      <td>inr</td>\n",
       "      <td>headline</td>\n",
       "      <td>swiss</td>\n",
       "      <td>shows</td>\n",
       "      <td>ax</td>\n",
       "      <td>coal</td>\n",
       "      <td>outlook</td>\n",
       "      <td>shows</td>\n",
       "      <td>italian</td>\n",
       "      <td>standings</td>\n",
       "      <td>liga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>emea</td>\n",
       "      <td>ca</td>\n",
       "      <td>moody</td>\n",
       "      <td>buzz</td>\n",
       "      <td>communications</td>\n",
       "      <td>sweden</td>\n",
       "      <td>standings</td>\n",
       "      <td>prix</td>\n",
       "      <td>west</td>\n",
       "      <td>weather</td>\n",
       "      <td>la</td>\n",
       "      <td>motorcycling</td>\n",
       "      <td>buzz</td>\n",
       "      <td>motorcycling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>motorcycling</td>\n",
       "      <td>los</td>\n",
       "      <td>motorcycling</td>\n",
       "      <td>motorcycling</td>\n",
       "      <td>refer</td>\n",
       "      <td>raises</td>\n",
       "      <td>championship</td>\n",
       "      <td>transmission</td>\n",
       "      <td>shut</td>\n",
       "      <td>baseball</td>\n",
       "      <td>liga</td>\n",
       "      <td>wins</td>\n",
       "      <td>aud</td>\n",
       "      <td>baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vs</td>\n",
       "      <td>prix</td>\n",
       "      <td>outlook</td>\n",
       "      <td>la</td>\n",
       "      <td>subsequent</td>\n",
       "      <td>pre</td>\n",
       "      <td>transmission</td>\n",
       "      <td>outage</td>\n",
       "      <td>returns</td>\n",
       "      <td>transmission</td>\n",
       "      <td>transmission</td>\n",
       "      <td>prix</td>\n",
       "      <td>jpy</td>\n",
       "      <td>transmission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>diary</td>\n",
       "      <td>table</td>\n",
       "      <td>championship</td>\n",
       "      <td>baseball</td>\n",
       "      <td>accessed</td>\n",
       "      <td>standings</td>\n",
       "      <td>outage</td>\n",
       "      <td>pjm</td>\n",
       "      <td>plant</td>\n",
       "      <td>outage</td>\n",
       "      <td>outage</td>\n",
       "      <td>la</td>\n",
       "      <td>momentum</td>\n",
       "      <td>outage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>taiwan</td>\n",
       "      <td>motorcycling</td>\n",
       "      <td>standings</td>\n",
       "      <td>liga</td>\n",
       "      <td>detailed</td>\n",
       "      <td>championship</td>\n",
       "      <td>pjm</td>\n",
       "      <td>motorcycling</td>\n",
       "      <td>mw</td>\n",
       "      <td>pjm</td>\n",
       "      <td>pjm</td>\n",
       "      <td>liga</td>\n",
       "      <td>baseball</td>\n",
       "      <td>pjm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3               4   \\\n",
       "0       spending          buzz            st            ns    ftseurofirst   \n",
       "1      corporate     standings        target           men            fuel   \n",
       "2          falls  championship       weather       holding           funds   \n",
       "3          nadal          sees      baseball   maintenance          future   \n",
       "4           prix    resistance         grand       singles         futures   \n",
       "5          shows          mail      research        volume            gain   \n",
       "6            lme         italy        raises      malaysia           gains   \n",
       "7        vietnam         grand          prix         doing            game   \n",
       "8        reports        rating        russia          prix        freeport   \n",
       "9             ca         moody        rating           inr        headline   \n",
       "10          emea            ca         moody          buzz  communications   \n",
       "11  motorcycling           los  motorcycling  motorcycling           refer   \n",
       "12            vs          prix       outlook            la      subsequent   \n",
       "13         diary         table  championship      baseball        accessed   \n",
       "14        taiwan  motorcycling     standings          liga        detailed   \n",
       "\n",
       "                5             6             7             8             9   \\\n",
       "0             fteu          buzz      freeport          fteu          fteu   \n",
       "1   communications      baseball          fteu  ftseurofirst  ftseurofirst   \n",
       "2           target         tokyo  ftseurofirst          fuel          fuel   \n",
       "3          outlook         white         funds         gains         funds   \n",
       "4          weather      research          fuel     frankfurt        future   \n",
       "5         baseball       holding       trading          gain       futures   \n",
       "6            qatar        rupees         italy       futures          gain   \n",
       "7         research        raises      baseball        future         gains   \n",
       "8         equities      holdings         grand          line     standings   \n",
       "9            swiss         shows            ax          coal       outlook   \n",
       "10          sweden     standings          prix          west       weather   \n",
       "11          raises  championship  transmission          shut      baseball   \n",
       "12             pre  transmission        outage       returns  transmission   \n",
       "13       standings        outage           pjm         plant        outage   \n",
       "14    championship           pjm  motorcycling            mw           pjm   \n",
       "\n",
       "              10            11            12            13  \n",
       "0      frankfurt        future          gain  championship  \n",
       "1           fuel     frankfurt       futures         grand  \n",
       "2          funds          free        future           usa  \n",
       "3            usd      freeport          free          post  \n",
       "4           play          fteu         funds         doing  \n",
       "5           buzz          form          zone          prix  \n",
       "6       stronger         funds  ftseurofirst            la  \n",
       "7         result          fuel          fteu       planned  \n",
       "8          cross         grand          fuel   maintenance  \n",
       "9          shows       italian     standings          liga  \n",
       "10            la  motorcycling          buzz  motorcycling  \n",
       "11          liga          wins           aud      baseball  \n",
       "12  transmission          prix           jpy  transmission  \n",
       "13        outage            la      momentum        outage  \n",
       "14           pjm          liga      baseball           pjm  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save to dataframe\n",
    "result = pd.DataFrame.from_dict({k : v['vocab'].tolist() for k, v in enumerate(result) })\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
