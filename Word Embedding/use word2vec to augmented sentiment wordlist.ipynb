{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file uses pre-trained w2v model to find similar words in the pos-neg word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import csv \n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn import metrics\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply pre-trained word2vec to the positive and negative word lists to find most similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. download word2vec model\n",
    "# ##specify download path and extract path \n",
    "# download_path = \"imf_w2v.zip\"\n",
    "# download_link = \"https://www.dropbox.com/sh/6um97x52kweebfx/AACSxB0E9weItCbyQwUqvuWRa?dl=1\"\n",
    "# extract_path = './data'\n",
    "# data_util.download_data(download_path,download_link,extract_path)\n",
    "\n",
    "#2. load pre-trained imf w2v model\n",
    "model_path = os.path.join('model','imf_160.w2v')\n",
    "imf_w2v = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data: 1. lists with positive and negative words; 2. economic news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "word_dict= pd.read_csv(os.path.join('../Sentiment Analysis','pos_neg_list.csv'))\n",
    "pos_list = word_dict[word_dict['Positive']==1]['Word'].tolist()\n",
    "neg_list = word_dict[word_dict['Negative']==1]['Word'].tolist()\n",
    "\n",
    "# define negation word list\n",
    "negation_list = ['not','no','nobody','none','never','neither','cannot']\n",
    "\n",
    "# 2.\n",
    "full_df = pd.read_csv(os.path.join('../Sentiment Analysis',\"economic_sentiment_data.csv\") )\n",
    "full_df = full_df[['sentence','sentiment','polarity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean and tokenize sentences for word2vec training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(raw):\n",
    "    '''clean a paragraph and breaks into sentences'''\n",
    "    raw = re.sub(r\"</br>\",\".\", raw)\n",
    "    raw = re.sub(r\"[.]+\",\".\", raw)\n",
    "    raw = re.sub(r\"[-+]?\\d*\\.\\d+|\\d+\",\"\", raw)\n",
    "    raw = re.sub(\"\\d\",\"\", raw)\n",
    "    raw = re.sub(r'[%-]',\"\", raw)\n",
    "    raw = sent_tokenize(raw)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = full_df.sentence.tolist()\n",
    "\n",
    "paragraphs = list(map(clean_text, paragraphs))\n",
    "\n",
    "sentences = [sent for para in paragraphs for sent in para ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(raw):\n",
    "    '''clean and tokenize each sentence into words'''\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words\n",
    "\n",
    "sentences = list(map(sentence_to_wordlist, sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate new negative list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original negative list length: 295\n",
      "Thse in the word2vec vocab: 288\n"
     ]
    }
   ],
   "source": [
    "# filter out those not in word2vec vocab\n",
    "print('Original negative list length: {}'.format(len(neg_list)))\n",
    "neg_list_org = [x for x in neg_list if x in imf_w2v.wv.vocab] \n",
    "print('Those in the word2vec vocab: {}'.format(len(neg_list_org)))\n",
    "neg_list_df = pd.DataFrame(neg_list_org, columns=['original_word']) # useful for merger later\n",
    "\n",
    "# get augmented list\n",
    "neg_df = list(map(lambda a: [[x[0],x[1]] for x in imf_w2v.wv.most_similar(a)], neg_list_org)) \n",
    "neg_df = list(map(pd.DataFrame, neg_df))\n",
    "neg_df = pd.concat(neg_df,axis = 0)\n",
    "\n",
    "neg_df['similarity_rank'] = neg_df.index\n",
    "neg_df.rename(columns={0: 'word', 1: 'similarity'},inplace= True)\n",
    "\n",
    "# merge with original word\n",
    "neg_df['original_word_rank'] = np.repeat(range(len(neg_list_org)),10)\n",
    "neg_df = neg_df.merge(neg_list_df, how = 'outer', left_on= 'original_word_rank', right_index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate new positive table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pos_list))\n",
    "pos_list_int = [x for x in pos_list if x in imf_w2v.wv.vocab] # filter out those not in word2vec vocab\n",
    "print(len(pos_list_int))\n",
    "\n",
    "pos_list_df = pd.DataFrame(pos_list_int, columns=['original_word'])\n",
    "pos_list_df.head()\n",
    "\n",
    "pos_list_aug = list(map(lambda a: [[x[0],x[1]] for x in imf_w2v.wv.most_similar(a)], pos_list_int))\n",
    "\n",
    "pos_df = list(map(pd.DataFrame, pos_list_aug))\n",
    "\n",
    "pos_df = pd.concat(pos_df,axis = 0)\n",
    "\n",
    "pos_df['similarity_rank'] = pos_df.index\n",
    "\n",
    "pos_df.rename(columns={0: 'word', 1: 'similarity'},inplace= True)\n",
    "\n",
    "np.repeat(a=(1,2,3) , repeats= 10)\n",
    "\n",
    "pos_df['original_word_rank'] = np.repeat(range(len(pos_list_int)),10)\n",
    "\n",
    "pos_df = pos_df.merge(pos_list_df, how = 'outer', left_on= 'original_word_rank', right_index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter and save based on: 1. similarity larger than 75 %ile; 2. new word not in the original word lists (pos & neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = pos_list + neg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_df = neg_df[(neg_df.similarity >= 0.623453) & (~neg_df.word.isin(full_list))]\n",
    "neg_df['original_word_label'] = 'negative'\n",
    "print(neg_df.shape)\n",
    "\n",
    "#pos_df.describe()\n",
    "pos_df = pos_df[(pos_df.similarity >= 0.593445) & (~pos_df.word.isin(full_list))]\n",
    "pos_df['original_word_label'] = 'positive'\n",
    "print(pos_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([neg_df , pos_df], axis = 0)\n",
    "\n",
    "full_df = full_df.groupby('word',as_index= False).agg({'similarity': 'max',\n",
    "                                            'original_word_rank': 'count',\n",
    "                                            'original_word': 'first',\n",
    "                                            'similarity_rank':'mean',\n",
    "                                            'original_word_label':'first'})\n",
    "\n",
    "full_df.rename({'similarity': 'max_sim', 'original_word_rank': 'count_in_original_word','similarity_rank':'mean_rank',\n",
    "               }, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(path = 'aug_pos_neg_list.xlsx')\n",
    "        \n",
    "full_df.to_excel(writer, 'full_df')\n",
    "\n",
    "writer.save()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
