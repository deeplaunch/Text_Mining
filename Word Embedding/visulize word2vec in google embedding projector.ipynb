{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file explores pre-trained w2v model using examples and tensorboard visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import csv \n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn import metrics\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply pre-trained word2vec to the positive and negative word lists to find most similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. download word2vec model\n",
    "# ##specify download path and extract path \n",
    "# download_path = \"imf_w2v.zip\"\n",
    "# download_link = \"https://www.dropbox.com/sh/6um97x52kweebfx/AACSxB0E9weItCbyQwUqvuWRa?dl=1\"\n",
    "# extract_path = './data'\n",
    "# data_util.download_data(download_path,download_link,extract_path)\n",
    "\n",
    "#2. load pre-trained imf w2v model\n",
    "model_path = os.path.join('model','imf_160.w2v')\n",
    "imf_w2v = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some examples to understand the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('malaysia', 0.7892636060714722),\n",
       " ('hong_kong', 0.7774065732955933),\n",
       " ('hong_kong_sar', 0.7603132128715515),\n",
       " ('thailand', 0.7355126738548279),\n",
       " ('korea', 0.7185163497924805),\n",
       " ('philippines', 0.6760509610176086),\n",
       " ('indonesia', 0.6705522537231445),\n",
       " ('taiwan_province', 0.649632453918457),\n",
       " ('new_zealand', 0.6455516219139099),\n",
       " ('sri_lanka', 0.6316699981689453)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imf_w2v.wv.most_similar('singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    '''find similar words'''\n",
    "    similarities = imf_w2v.wv.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    \n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is to {end1}, like {start2} is to {end2}\".format(**locals()))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmb is to china, like rs is to india\n",
      "manufacturing is to china, like restaurants is to singapore\n"
     ]
    }
   ],
   "source": [
    "nearest_similarity_cosmul('rmb','china','india')\n",
    "nearest_similarity_cosmul('manufacturing','china','singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('electronics', 0.6150177121162415)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imf_w2v.wv.most_similar(positive =['china','manufacturing'],negative =['india'], topn =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model to tensorflow [embedding projector](https://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_for_visulization(model, output_path, meta_file = \"imf_w2v_metadata.tsv\", vector_file = \"imf_w2v_vectordata.tsv\"):\n",
    "\n",
    "    with open(os.path.join(output_path,vector_file), 'wb') as file_vector:\n",
    "        with open(os.path.join(output_path,meta_file), 'wb') as file_metadata:\n",
    "            \n",
    "            for word in model.wv.index2word:\n",
    "                file_metadata.write('{0}'.format(word).encode('utf-8') + '\\n'.encode('utf-8'))                \n",
    "                vector_row = '\\t'.join(map(str, model.wv.word_vec(word)))\n",
    "                file_vector.write(gensim.utils.to_utf8(vector_row) + '\\n'.encode('utf-8'))\n",
    "\n",
    "    return None\n",
    "\n",
    "save_for_visulization(model = imf_w2v, output_path = 'model/tensorboard')\n",
    "\n",
    "# word2vec_model_path = model_path\n",
    "# tensor_filename = 'model\\tensorboard'\n",
    "# gensim.scripts.word2vec2tensor(word2vec_model_path,tensor_filename,binary=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
