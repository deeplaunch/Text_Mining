{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### inspired by https://github.com/explosion/spacy-pytorch-transformers/blob/master/examples/train_textcat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  load csv and convert to json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3750, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.getcwd()\n",
    "\n",
    "def load_directory_data(directory):\n",
    "  \n",
    "  # data = load_directory_data(os.path.join(directory, \"economic_sentiment_data.csv\"))\n",
    "\n",
    "  data = pd.read_csv(os.path.join(directory, \"economic_sentiment_data.csv\"))\n",
    "  \n",
    "  data = data[['sentence','polarity']]\n",
    "  \n",
    "  print(data.shape)\n",
    "\n",
    "  return data\n",
    "\n",
    "data_folder = '../data/'\n",
    "full_data_df = load_directory_data(data_folder)\n",
    "\n",
    "train_df = full_data_df.iloc[:3000]\n",
    "test_df = full_data_df.iloc[3000:]\n",
    "\n",
    "# convert to json\n",
    "train_df.to_json( os.path.join(data_folder, 'train.json'), orient= 'index')\n",
    "test_df.to_json(os.path.join(data_folder,'test.json'), orient= 'index', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load json as dictionary, convert to list of tuples as required by spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "train_json_str = train_df.to_json(orient= 'index')\n",
    "test_json_str = test_df.to_json(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = json.loads(train_json_str)\n",
    "test_json = json.loads(test_json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA =[]\n",
    "\n",
    "for v in train_json.values():\n",
    "    TRAIN_DATA.append((v['sentence'],{'cats':{'POSITIVE': v['polarity'],'NEGATIVE': 1-v['polarity']}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA =[]\n",
    "for v in test_json.values():\n",
    "    TEST_DATA.append((v['sentence'],{'cats':{'POSITIVE': v['polarity'],'NEGATIVE': 1-v['polarity']}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import rhinoscriptsyntax as rs\n",
    "# import json\n",
    "\n",
    "# #prompt the user for a file to import\n",
    "# filter = \"JSON file (*.json)|*.json|All Files (*.*)|*.*||\"\n",
    "# filename = rs.OpenFileName(\"Open JSON File\", filter)\n",
    "\n",
    "# with open(os.path.join(data_folder, 'train.json'),'r') as file:\n",
    "#     train_json = file.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.util import minibatch\n",
    "import random\n",
    "spacy.prefer_gpu()\n",
    "import torch\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "\n",
    "nlp = spacy.load(\"en_pytt_bertbaseuncased_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencizer', 'pytt_wordpiecer', 'pytt_tok2vec']\n",
      "['sentencizer', 'pytt_wordpiecer', 'pytt_tok2vec', 'pytt_textcat']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names) # [\"sentencizer\", \"pytt_wordpiecer\", \"pytt_tok2vec\"]\n",
    "textcat = nlp.create_pipe(\"pytt_textcat\", config={\"exclusive_classes\": True})\n",
    "for label in (\"POSITIVE\", \"NEGATIVE\"):\n",
    "    textcat.add_label(label)\n",
    "nlp.add_pipe(textcat)\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training is very slow, 25 minutes per epoch on large machine with CPU\n",
    "## on GPU: to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = nlp.resume_training()\n",
    "\n",
    "for i in range(3):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for batch in minibatch(TRAIN_DATA, size=32):\n",
    "        texts, cats = zip(*batch)\n",
    "        nlp.update(texts, cats, sgd=optimizer, losses=losses, drop=0.1)\n",
    "    #scores = nlp.evaluate(TEST_DATA)\n",
    "    print(i, losses) #scores, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0 {'pytt_textcat': 0.0007305766448553186}\n",
    "##### 1 {'pytt_textcat': 0.0005921392457821639}\n",
    "##### 2 {'pytt_textcat': 0.0004447193523446913}\n",
    "##### 3 {'pytt_textcat': 0.0003327218119011377}\n",
    "##### 4 {'pytt_textcat': 0.000254198645507131}\n",
    "##### 5 {'pytt_textcat': 0.011014029983925866}\n",
    "##### 6 {'pytt_textcat': 0.008851727914588992}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(nlp, texts, cats):\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 0.0  # False positives\n",
    "    fn = 0.0  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    total_words = sum(len(text.split()) for text in texts)\n",
    "    with tqdm.tqdm(total=total_words, leave=False) as pbar:\n",
    "        for i, doc in enumerate(nlp.pipe(texts, batch_size=128)):\n",
    "            gold = cats[i]['cats']\n",
    "            for label, score in doc.cats.items():\n",
    "                if label not in gold:\n",
    "                    continue\n",
    "                if label == \"NEGATIVE\":\n",
    "                    continue\n",
    "                if score >= 0.5 and gold[label] >= 0.5:\n",
    "                    tp += 1.0\n",
    "                elif score >= 0.5 and gold[label] < 0.5:\n",
    "                    fp += 1.0\n",
    "                elif score < 0.5 and gold[label] < 0.5:\n",
    "                    tn += 1\n",
    "                elif score < 0.5 and gold[label] >= 0.5:\n",
    "                    fn += 1\n",
    "            pbar.update(len(doc.text.split()))\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_texts, eval_cats = zip(*TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'textcat_f': 0.6401273885146456,\n",
       " 'textcat_p': 0.5661971830826423,\n",
       " 'textcat_r': 0.7362637362367669}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(nlp, eval_texts[:], eval_cats[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###{'textcat_f': 0.6401273885146456,\n",
    "### 'textcat_p': 0.5661971830826423,\n",
    "### 'textcat_r': 0.7362637362367669}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some tests using articles from today's FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indian shares endured their worst July in 17 years, a sign that stewing trouble in the country’s economy has been catching up with the stock market after a stellar run. {'POSITIVE': 0.0, 'NEGATIVE': 1.0}\n",
      "KKR has won the race to buy German payments group Heidelpay for more than €600m in a fresh sign of investor appetite for companies that offer digital alternatives to cash. {'POSITIVE': 1.0, 'NEGATIVE': 0.0}\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Indian shares endured their worst July in 17 years, a sign that stewing trouble in the country’s economy has been catching up with the stock market after a stellar run.\"\n",
    "doc = nlp(test_text)\n",
    "print(test_text, doc.cats)\n",
    "\n",
    "test_text = \"KKR has won the race to buy German payments group Heidelpay for more than €600m in a fresh sign of investor appetite for companies that offer digital alternatives to cash.\"\n",
    "doc = nlp(test_text)\n",
    "print(test_text, doc.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp.to_disk(\"../model/bert-textcat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
