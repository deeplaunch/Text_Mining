{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Keyword Extraction Using Staistical Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/Model'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import pke\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "from nltk import download\n",
    "download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "output_dir = '../Output/'\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stoplist = list(string.punctuation)\n",
    "stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
    "stoplist += stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions = pd.read_excel(os.path.join(output_dir,'Submissions_test.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_key_words(text, method, n_word = 10):\n",
    "    '''\n",
    "    input: text- string, method: string key for extractor_list\n",
    "    output: list of top key words extracted\n",
    "    '''\n",
    "    extractor_dict = {\n",
    "        ## statiscal methods:\n",
    "        'tfidf': pke.unsupervised.TfIdf(),\n",
    "        'kp miner': pke.unsupervised.KPMiner(),\n",
    "        'YAKE': pke.unsupervised.YAKE()\n",
    "    }\n",
    "    \n",
    "    df= pke.load_document_frequency_file(input_file='../Output/output.tsv.gz')\n",
    "    extractor = extractor_dict[method]\n",
    "    extractor.load_document(input= text, language='en', normalization='stemming')\n",
    "    # keyphrase candidate selection\n",
    "    if (method in('tfidf','kp miner')):\n",
    "        extractor.candidate_selection(stoplist = stoplist)\n",
    "        extractor.candidate_weighting(df= df)\n",
    "    else:\n",
    "        extractor.candidate_selection()\n",
    "        extractor.candidate_weighting()\n",
    "\n",
    "    keyphrases = extractor.get_n_best(n= n_word) # get key phrases\n",
    "    \n",
    "    return keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for key in ['tfidf', 'kp miner', 'YAKE']:\n",
    "    print('Keyword extraction using key: ', key, r'...')\n",
    "    submissions[key] = submissions.Description.apply(lambda x: extract_key_words(x, key, n_word= 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.to_csv('../Output/Submissions_with_Keyword_Extraction_Statistical.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick one for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "text = submissions.loc[i, 'Description']\n",
    "print (submissions.loc[i,'Title_modified'])\n",
    "#### Visuzliae Entity\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent', jupyter= True)\n",
    "#### Print out keywords Extracted\n",
    "for key in ['tfidf', 'kp miner', 'YAKE']:\n",
    "    print('Keyword extraction using: ', key, r'...')\n",
    "    print(extract_key_words(text, key, n_word= 6), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Need to run the followint to Create and Save Document Frequency File (in separate file)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def save_document(name, text):\n",
    "    with open(os.path.join(output_dir,'Document/', str(name)+'.txt'), \"w\") as text_file:\n",
    "        text_file.write(text)\n",
    "\n",
    "submissions[['Title_modified','Description']].apply(lambda x: save_document(x[0],x[1]), axis=1)\n",
    "\n",
    "from pke import compute_document_frequency\n",
    "\n",
    "compute_document_frequency?\n",
    "\n",
    "compute_document_frequency(input_dir=os.path.join(output_dir,'Document'),\n",
    "                           output_file= os.path.join(output_dir,'output.tsv.gz'),\n",
    "                           extension='txt',           # input file extension\n",
    "                           language='en',                # language of files\n",
    "                           normalization=\"stemming\",    # use porter stemmer\n",
    "                           stoplist=stoplist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
