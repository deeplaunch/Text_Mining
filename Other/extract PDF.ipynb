{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchList = ['FinTech','TechFin','digital','technology','Blockchain',\n",
    "              'distributed','Bitcoin','ICO','cryptocurrency','mobile','online',\n",
    "              'cyber','InsurTech','RegTech','micro']\n",
    "\n",
    "searchList = [x.lower() for x in searchList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = r'U:\\\\My Documents\\\\Python\\\\Text Mining\\\\PDF Extraction\\files'\n",
    "\n",
    "file_name = os.listdir(input_folder)\n",
    "file_path = [os.path.join(input_folder, x) for x in file_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, fake_file_handle)\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    " \n",
    "    with open(pdf_path, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, \n",
    "                                      caching=True,\n",
    "                                      check_extractable=True):\n",
    "            page_interpreter.process_page(page)\n",
    " \n",
    "        text = fake_file_handle.getvalue()\n",
    " \n",
    "    # close open handles\n",
    "    converter.close()\n",
    "    fake_file_handle.close()\n",
    " \n",
    "    if text:\n",
    "        return text\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    doc_list = list(map(lambda x: extract_text_from_pdf(x), file_path))\n",
    "    print(len(doc_list)) #     print(extract_text_from_pdf(file_path[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = list(map(lambda x: sent_tokenize(x), doc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_document(doc, word_l= searchList, n_sentences = 5):\n",
    "    '''return +/- n_sentences around key words in list word_l'''\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for counter, sent in enumerate(doc):\n",
    "        sent_lower = word_tokenize(sent.lower())\n",
    "        if any(w in word_l for w in sent_lower):\n",
    "            result.append(doc[counter - n_sentences : counter + n_sentences])    \n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent = [search_document(doc = x) for x in doc_list]\n",
    "\n",
    "title = [x[1] for x in doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data={'title': title, 'sentences': pos_sent, 'file': file_name})\n",
    "\n",
    "output_long = output.apply(lambda x: pd.Series(x['sentences']), axis = 1).stack().reset_index(level=1, drop = True)\n",
    "\n",
    "output_long.name = 'context'\n",
    "\n",
    "output_long = pd.DataFrame(output_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = pd.merge(output, output_long, how = 'outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output[['title','file','context']].to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def find_key_words(document, word_l = searchList):\n",
    "    \n",
    "\n",
    "# import spacy\n",
    "\n",
    "# !python -m spacy download en\n",
    "\n",
    "# nlp = spacy.load('en')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
